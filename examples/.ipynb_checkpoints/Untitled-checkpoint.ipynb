{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "import jax\n",
    "from jax import jit, grad, vmap\n",
    "import jax.numpy as np\n",
    "\n",
    "import numpy as onp\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "from fastax import optimizers\n",
    "from fastax.layers import Sigmoid, elementwise, serial, LSTM\n",
    "# from fastax.activations import \n",
    "from fastax.losses import create_loss, crossentropy as cse\n",
    "from fastax.initializers import glorot_uniform\n",
    "from data import train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 unique words found\n"
     ]
    }
   ],
   "source": [
    "vocab = list(set([w for text in train_data.keys() for w in text.split(' ')]))\n",
    "vocab_size = len(vocab)\n",
    "print('%d unique words found' % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign indices to each word.\n",
    "word_to_idx = { w: i for i, w in enumerate(vocab) }\n",
    "idx_to_word = { i: w for i, w in enumerate(vocab) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createInputs(text):\n",
    "    '''\n",
    "      Returns an array of one-hot vectors representing the words in the input text string.\n",
    "      - text is a string\n",
    "      - Each one-hot vector has shape (vocab_size, 1)\n",
    "    '''\n",
    "    inputs = []\n",
    "    for w in text.split(' '):\n",
    "        v = onp.zeros((vocab_size, 1))\n",
    "        v[word_to_idx[w]] = 1\n",
    "        inputs.append(np.transpose(v))\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax = elementwise(softmax)\n",
    "init_random_params, net = serial(LSTM(2, W_init=glorot_uniform), Sigmoid)\n",
    "\n",
    "loss_cse = create_loss(net, cse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_grad = jit(grad(loss_cse))\n",
    "\n",
    "def update(i, opt_state, batch):\n",
    "    params = get_params(opt_state)\n",
    "    x, y = batch\n",
    "    grads = loss_grad(params, x, y)\n",
    "#     print(grads, \"\\n\\n\\n\")\n",
    "    return opt_update(i, grads, opt_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(data, i, opt_state, net, backprop=True):\n",
    "    '''\n",
    "    Returns the RNN's loss and accuracy for the given data.\n",
    "    - data is a dictionary mapping text to True or False.\n",
    "    - backprop determines if the backward phase should be run.\n",
    "    '''\n",
    "    items = list(data.items())\n",
    "    random.shuffle(items)\n",
    "\n",
    "    loss = 0\n",
    "    num_correct = 0\n",
    "    cnt = 0\n",
    "\n",
    "    for x, y in items:\n",
    "        inputs = createInputs(x)\n",
    "        target = int(y)\n",
    "        params = get_params(opt_state)\n",
    "        \n",
    "        # Forward\n",
    "        probs = net(params, inputs)\n",
    "\n",
    "        # Calculate loss / accuracy\n",
    "        num_correct += int(np.argmax(probs) == target)\n",
    "        if backprop:\n",
    "            opt_state = update(i*len(data) + cnt, opt_state, (inputs, y))\n",
    "            cnt += 1\n",
    "    return opt_state, num_correct/len(data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john/anaconda3/envs/jax/lib/python3.7/site-packages/jax/lib/xla_bridge.py:114: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    }
   ],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "\n",
    "opt_init, opt_update, get_params = optimizers.sgd(0.02)\n",
    "_, init_params = init_random_params(rng, (18, 1))\n",
    "opt_state = opt_init(init_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 100\n",
      "Train Accuracy: 0.552\n",
      "Test Accuracy: 0.500\n",
      "--- Epoch 200\n",
      "Train Accuracy: 0.431\n",
      "Test Accuracy: 0.350\n",
      "--- Epoch 300\n",
      "Train Accuracy: 0.776\n",
      "Test Accuracy: 0.700\n",
      "--- Epoch 400\n",
      "Train Accuracy: 0.793\n",
      "Test Accuracy: 0.700\n",
      "--- Epoch 500\n",
      "Train Accuracy: 0.828\n",
      "Test Accuracy: 0.750\n",
      "--- Epoch 600\n",
      "Train Accuracy: 0.948\n",
      "Test Accuracy: 0.950\n",
      "--- Epoch 700\n",
      "Train Accuracy: 0.983\n",
      "Test Accuracy: 0.950\n",
      "--- Epoch 800\n",
      "Train Accuracy: 1.000\n",
      "Test Accuracy: 1.000\n",
      "--- Epoch 900\n",
      "Train Accuracy: 1.000\n",
      "Test Accuracy: 1.000\n",
      "--- Epoch 1000\n",
      "Train Accuracy: 1.000\n",
      "Test Accuracy: 0.900\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    opt_state, train_acc = processData(train_data, epoch, opt_state, net)\n",
    "\n",
    "    if epoch % 100 == 99:\n",
    "        print('--- Epoch %d' % (epoch + 1))\n",
    "        print('Train Accuracy: %.3f' % (train_acc))\n",
    "\n",
    "        _, test_acc = processData(test_data, epoch, opt_state, net, backprop=False)\n",
    "        print('Test Accuracy: %.3f' % (test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
